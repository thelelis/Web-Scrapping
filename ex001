import requests
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
import pandas as pd
import time

path = 'C:\Program Files (x86)\chromedriver.exe'
url = 'http://www.yahii.com.br/inpc.html'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

table = soup.find('table', {'cellpadding': '2'})
rows = soup.findAll('table')[0].findAll('tr')
columns = [v.text.replace('\n', '') for v in rows[0].find_all('th')]

df = pd.DataFrame(columns=columns)

for i in range(1, len(rows)):
    tds = rows[i].find_all('td')

    df = df.append(pd.Series(values, index=columns), ignore_index=True)

    df.to_excel(r'C:\Users\Lelis\Documents\Programação\Python\Projetos Web\Web Scrapping\wiki' + '\\manufacturetop10.xlsx', index=False)


print(df)
